{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhinavkrishna3211/EleTect/blob/main/notebooks/en/Gesture_Detection_Swift-YOLO_192.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrl5DMtFJYl-"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <h1>Welcom to SSCMA for Google Colab Training Example ðŸ”¥ </h1>\n",
        "  <a href=\"https://sensecraftma.seeed.cc/\" target=\"_blank\"><img width=\"20%\" src=\"https://files.seeedstudio.com/sscma/docs/images/SSCMA-Hero.png\"></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE5xXkbRJYmA"
      },
      "source": [
        "## âš ï¸ Important Notice\n",
        "\n",
        "Before you begin, please ensure:\n",
        "\n",
        "1. **Enable GPU Acceleration**: Click `Runtime` â†’ `Change runtime type` â†’ Select `GPU` in `Hardware accelerator`\n",
        "2. **Colab Version Requirement**: **You MUST use Colab version 2025.07** for compatibility. Other versions may cause unexpected errors.\n",
        "\n",
        "If you encounter version-related issues, you can run the following commands in the first code cell to check your environment:\n",
        "\n",
        "```python\n",
        "# Check if GPU is available\n",
        "!nvidia-smi\n",
        "\n",
        "# Check Python version\n",
        "!python --version\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfiAYK38JYmB"
      },
      "source": [
        "# Gesture Detection - Swift-YOLO\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seeed-studio/sscma-model-zoo/blob/main/notebooks/en/Gesture_Detection_Swift-YOLO_192.ipynb)\n",
        "\n",
        "**Version:** 1.0.0\n",
        "\n",
        "**Category:** Object Detection\n",
        "\n",
        "**Algorithm:** [Swift-YOLO](configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py)\n",
        "\n",
        "**Dataset:** [Gesture](https://universe.roboflow.com/rsp/paper-aaj0p/dataset/33)\n",
        "\n",
        "**Class:** `paper`, `rock`, `scissors`\n",
        "\n",
        "![Gesture Detection](https://files.seeedstudio.com/sscma/static/detection_gesture.png)\n",
        "\n",
        "The model is a Swift-YOLO model trained on the gesture detection dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEkM_2CmJYmB"
      },
      "source": [
        "## âš™ï¸Prerequisites\n",
        "### Setup SSCMA\n",
        "Clone the [repository](https://github.com/Seeed-Studio/ModelAssistant) and install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssAmBtXWJYmC",
        "outputId": "9903bf07-1f57-4ec8-95fb-3b2d88b6cf99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ethos-u-vela'...\n",
            "fatal: https://review.mlplatform.org/ml/ethos-u/ethos-u-vela.git/info/refs not valid: is this a git repository?\n",
            "[Errno 2] No such file or directory: 'ethos-u-vela'\n",
            "/content\n",
            "\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m/\n",
            "Cloning into 'ModelAssistant'...\n",
            "remote: Enumerating objects: 15755, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 15755 (delta 7), reused 17 (delta 2), pack-reused 15719 (from 1)\u001b[K\n",
            "Receiving objects: 100% (15755/15755), 26.60 MiB | 28.83 MiB/s, done.\n",
            "Resolving deltas: 100% (9193/9193), done.\n",
            "/ModelAssistant\n",
            "Checking if CUDA available... \u001b[032mOK\u001b[m\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting torchaudio==2.0.1\n",
            "  Downloading torchaudio-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (11.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.0.1-cp311-cp311-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n"
          ]
        }
      ],
      "source": [
        "# Ethos-U-Vela need to be installed this way, or SSCMA does not work anymore...\n",
        "!git clone https://review.mlplatform.org/ml/ethos-u/ethos-u-vela.git\n",
        "%cd ethos-u-vela\n",
        "!pip install .\n",
        "%cd ..\n",
        "\n",
        "!git clone https://github.com/Seeed-Studio/ModelAssistant.git -b 2.0.0  #clone the repo\n",
        "%cd ModelAssistant\n",
        "!. ./scripts/setup_colab.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLzlxM2lJYmD"
      },
      "source": [
        "### Download the pretrain model weights file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "30umVdDHJYmD",
        "outputId": "7fd82ece-7f9d-4c7b-c6c7-134d3da9fafc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-30 14:33:18--  https://files.seeedstudio.com/sscma/model_zoo/detection/gesture/swift_yolo_1xb16_300e_coco_sha1_adda465db843aae8384c90c82e223c2cd931cad2.pth\n",
            "Resolving files.seeedstudio.com (files.seeedstudio.com)... 108.157.254.102, 108.157.254.78, 108.157.254.103, ...\n",
            "Connecting to files.seeedstudio.com (files.seeedstudio.com)|108.157.254.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12822891 (12M) [application/octet-stream]\n",
            "Saving to: â€˜Gesture_Detection_Swift-YOLO_192/pretrain.pthâ€™\n",
            "\n",
            "Gesture_Detection_S 100%[===================>]  12.23M  8.14MB/s    in 1.5s    \n",
            "\n",
            "2025-11-30 14:33:20 (8.14 MB/s) - â€˜Gesture_Detection_Swift-YOLO_192/pretrain.pthâ€™ saved [12822891/12822891]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p Gesture_Detection_Swift-YOLO_192\n",
        "!wget -c https://files.seeedstudio.com/sscma/model_zoo/detection/gesture/swift_yolo_1xb16_300e_coco_sha1_adda465db843aae8384c90c82e223c2cd931cad2.pth -O Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viVrsz6mJYmE"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u97Y9Lf3JYmE",
        "outputId": "afe8665c-4955-4390-cdfc-70517e5ba8f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-30 14:33:31--  https://app.roboflow.com/ds/uQS9v4ZUkd?key=8d2CgUki6U\n",
            "Resolving app.roboflow.com (app.roboflow.com)... 151.101.1.195, 151.101.65.195, 2620:0:890::100\n",
            "Connecting to app.roboflow.com (app.roboflow.com)|151.101.1.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/roboflow-platform-regional-exports/VLM8F9Ir57QwpsUBz9ZUJ3DYGPg1/RsjlN9g6hTDSGpkSPhBr/1/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20251130%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20251130T143331Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=82bc82843ad40879e3eced30d57409dd7dc890e8177f67188effda1efcf3cb7a91c0cab3976bc1afd815c2fa70bc053736c6cdbdaf353bf98d78ee111446949043369b640dd61af64c94369d2512b4f0c4711c5f783b10f3ede768a6bb49e92f2aa4b5237897786efb852a0e60deeee28a0de889be7ae4c281431d884a1d18a0e2ecec404fd0aefd517170bc9c643ec0750c424081192ced8fa31172056670648369fbb8132fce55d52e2f871c644ec1f5d5e2ba840c09aa7af7f41589866fdcaa3107836b3e02ffca5f48557e98d45b253b95bf6e85760b6a5f07d2357d11a021356dbcaa45bdb03ba82cd03d1f350bfd0580fc6a546319f037aa48ee53a3c4 [following]\n",
            "--2025-11-30 14:33:32--  https://storage.googleapis.com/roboflow-platform-regional-exports/VLM8F9Ir57QwpsUBz9ZUJ3DYGPg1/RsjlN9g6hTDSGpkSPhBr/1/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20251130%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20251130T143331Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=82bc82843ad40879e3eced30d57409dd7dc890e8177f67188effda1efcf3cb7a91c0cab3976bc1afd815c2fa70bc053736c6cdbdaf353bf98d78ee111446949043369b640dd61af64c94369d2512b4f0c4711c5f783b10f3ede768a6bb49e92f2aa4b5237897786efb852a0e60deeee28a0de889be7ae4c281431d884a1d18a0e2ecec404fd0aefd517170bc9c643ec0750c424081192ced8fa31172056670648369fbb8132fce55d52e2f871c644ec1f5d5e2ba840c09aa7af7f41589866fdcaa3107836b3e02ffca5f48557e98d45b253b95bf6e85760b6a5f07d2357d11a021356dbcaa45bdb03ba82cd03d1f350bfd0580fc6a546319f037aa48ee53a3c4\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.118.207, 172.217.194.207, 142.251.10.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.118.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 813624041 (776M) [application/zip]\n",
            "Saving to: â€˜Gesture_Detection_Swift-YOLO_192/dataset.zipâ€™\n",
            "\n",
            "Gesture_Detection_S 100%[===================>] 775.93M  17.9MB/s    in 45s     \n",
            "\n",
            "2025-11-30 14:34:18 (17.2 MB/s) - â€˜Gesture_Detection_Swift-YOLO_192/dataset.zipâ€™ saved [813624041/813624041]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p Gesture_Detection_Swift-YOLO_192/dataset\n",
        "!wget -c https://app.roboflow.com/ds/uQS9v4ZUkd?key=8d2CgUki6U -O Gesture_Detection_Swift-YOLO_192/dataset.zip\n",
        "!unzip -q Gesture_Detection_Swift-YOLO_192/dataset.zip -d Gesture_Detection_Swift-YOLO_192/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmsPebPCJYmF"
      },
      "source": [
        "## ðŸš€Train a model with SSCMA\n",
        "All the training parameters are in the `config.py` file, you can change the parameters to train your own model.\n",
        "\n",
        "Below are explanations of some common parameters. You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/config) for more details.\n",
        "- `data_root` - the datasets path.\n",
        "- `epochs`- the train epochs. **we use 10 epochs as an example**.\n",
        "- `batch_size` - the batch size.\n",
        "- `height` - the image height.\n",
        "- `width` - the image width.\n",
        "- `load_from` - the pretrained model path.\n",
        "- `num_classes` - the number of classes.\n",
        "\n",
        "You can overwrite the parameters in the `config.py` file by using the `--cfg-options` argument.\n",
        "```bash\n",
        "# Example\n",
        "sscma.train config.py --cfg-options data_root=./datasets/test_dataset epochs=10\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu1B3FLoJYmF",
        "outputId": "21149f19-f6f4-4a66-ec87-9f97bfc21431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.0\n",
            "Using automatically generated input shape (from config 'swift_yolo_tiny_1xb16_300e_coco.py'): [1, 3, 192, 192]\n",
            "11/30 14:35:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 173211492\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.5, V12.5.82\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.11.0\n",
            "    MMEngine: 0.10.7\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 173211492\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "11/30 14:35:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=192,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'Gesture_Detection_Swift-YOLO_192/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=15,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 15\n",
            "height = 192\n",
            "imgsz = (\n",
            "    192,\n",
            "    192,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = 'Gesture_Detection_Swift-YOLO_192/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=12,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.075,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=0.09000000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 12\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        192,\n",
            "        192,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=15, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -96,\n",
            "                    -96,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            192,\n",
            "            192,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -96,\n",
            "            -96,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=192,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='Gesture_Detection_Swift-YOLO_192/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                192,\n",
            "                192,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    192,\n",
            "                    192,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'Gesture_Detection_Swift-YOLO_192/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 192\n",
            "work_dir = 'Gesture_Detection_Swift-YOLO_192'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/ModelAssistant/Gesture_Detection_Swift-YOLO_192/20251130_143514'}\n",
            "2025-11-30 14:35:16.981074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "11/30 14:35:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "11/30 14:35:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "[1, 3, 192, 192]\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::add encountered 24 time(s)\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::sigmoid encountered 3 time(s)\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::mul encountered 18 time(s)\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::meshgrid encountered 3 time(s)\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::clone encountered 3 time(s)\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::sub encountered 3 time(s)\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::mul_ encountered 6 time(s)\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "bbox_head.head_module.data_preprocessor, bbox_head.loss_bbox, bbox_head.loss_cls, bbox_head.loss_obj, data_preprocessor\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::batch_norm encountered 85 time(s)\n",
            "11/30 14:35:30 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::upsample_nearest2d encountered 2 time(s)\n",
            "\n",
            "+---------------------------+----------------------+------------+--------------+\n",
            "|\u001b[1m \u001b[0m\u001b[1mmodule                   \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#parameters or shape\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#flops    \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#activations\u001b[0m\u001b[1m \u001b[0m|\n",
            "+---------------------------+----------------------+------------+--------------+\n",
            "| model                     | 0.953M               | 0.127G     | 1.079M       |\n",
            "|  backbone                 |  0.66M               |  0.101G    |  0.868M      |\n",
            "|   backbone.stem.conv      |   1.76K              |   16.22M   |   0.147M     |\n",
            "|    backbone.stem.conv.coâ€¦ |    1.728K            |    15.925M |    0.147M    |\n",
            "|    backbone.stem.conv.noâ€¦ |    32                |    0.295M  |    0         |\n",
            "|   backbone.stage1         |   9.216K             |   21.234M  |   0.332M     |\n",
            "|    backbone.stage1.0.conv |    3.504K            |    8.073M  |    55.296K   |\n",
            "|    backbone.stage1.1      |    5.712K            |    13.16M  |    0.276M    |\n",
            "|   backbone.stage2         |   36.56K             |   21.059M  |   0.207M     |\n",
            "|    backbone.stage2.0.conv |    8.72K             |    5.023M  |    23.04K    |\n",
            "|    backbone.stage2.1      |    27.84K            |    16.036M |    0.184M    |\n",
            "|   backbone.stage3         |   0.188M             |   27.003M  |   0.138M     |\n",
            "|    backbone.stage3.0.conv |    28.96K            |    4.17M   |    11.52K    |\n",
            "|    backbone.stage3.1      |    0.159M            |    22.833M |    0.127M    |\n",
            "|   backbone.stage4         |   0.425M             |   15.293M  |   43.2K      |\n",
            "|    backbone.stage4.0.conv |    0.116M            |    4.159M  |    5.76K     |\n",
            "|    backbone.stage4.1      |    0.245M            |    8.813M  |    28.8K     |\n",
            "|    backbone.stage4.2      |    64.48K            |    2.321M  |    8.64K     |\n",
            "|  neck                     |  0.279M              |  23.881M   |  0.173M      |\n",
            "|   neck.reduce_layers.2.câ€¦ |   12.96K             |   0.467M   |   2.88K      |\n",
            "|    neck.reduce_layers.2.â€¦ |    12.8K             |    0.461M  |    2.88K     |\n",
            "|    neck.reduce_layers.2.â€¦ |    0.16K             |    5.76K   |    0         |\n",
            "|   neck.top_down_layers    |   48K                |   10.817M  |   0.109M     |\n",
            "|    neck.top_down_layers.0 |    38.96K            |    5.61M   |    40.32K    |\n",
            "|    neck.top_down_layers.1 |    9.04K             |    5.207M  |    69.12K    |\n",
            "|   neck.downsample_layers  |   72.24K             |   4.164M   |   8.64K      |\n",
            "|    neck.downsample_layerâ€¦ |    14.48K            |    2.085M  |    5.76K     |\n",
            "|    neck.downsample_layerâ€¦ |    57.76K            |    2.079M  |    2.88K     |\n",
            "|   neck.bottom_up_layers   |   0.145M             |   8.398M   |   51.84K     |\n",
            "|    neck.bottom_up_layersâ€¦ |    29.28K            |    4.216M  |    34.56K    |\n",
            "|    neck.bottom_up_layersâ€¦ |    0.116M            |    4.182M  |    17.28K    |\n",
            "|   neck.upsample_layers    |                      |   34.56K   |   0          |\n",
            "|    neck.upsample_layers.0 |                      |    11.52K  |    0         |\n",
            "|    neck.upsample_layers.1 |                      |    23.04K  |    0         |\n",
            "|  bbox_head.head_module.câ€¦ |  14.433K             |  2.056M    |  38.556K     |\n",
            "|   bbox_head.head_module.â€¦ |   2.091K             |   1.175M   |   29.376K    |\n",
            "|    bbox_head.head_moduleâ€¦ |    (51, 40, 1, 1)    |            |              |\n",
            "|    bbox_head.head_moduleâ€¦ |    (51,)             |            |              |\n",
            "|   bbox_head.head_module.â€¦ |   4.131K             |   0.588M   |   7.344K     |\n",
            "|    bbox_head.head_moduleâ€¦ |    (51, 80, 1, 1)    |            |              |\n",
            "|    bbox_head.head_moduleâ€¦ |    (51,)             |            |              |\n",
            "|   bbox_head.head_module.â€¦ |   8.211K             |   0.294M   |   1.836K     |\n",
            "|    bbox_head.head_moduleâ€¦ |    (51, 160, 1, 1)   |            |              |\n",
            "|    bbox_head.head_moduleâ€¦ |    (51,)             |            |              |\n",
            "+---------------------------+----------------------+------------+--------------+\n",
            "\n",
            "========================================\n",
            "    Input Shape     :  [1, 3, 192, 192]  \n",
            "    Model Flops     :       0.127G       \n",
            "  Model Parameters  :       0.953M       \n",
            "========================================\n",
            "loading annotations into memory...\n",
            "Done (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "11/30 14:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Optimizer groups: 88 .bias, 88 conv.weight, 85 other\n",
            "Loads checkpoint by local backend from path: Gesture_Detection_Swift-YOLO_192/pretrain.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for bbox_head.head_module.convs_pred.0.weight: copying a param with shape torch.Size([24, 40, 1, 1]) from checkpoint, the shape in current model is torch.Size([51, 40, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.0.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([51]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.1.weight: copying a param with shape torch.Size([24, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([51, 80, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.1.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([51]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.2.weight: copying a param with shape torch.Size([24, 160, 1, 1]) from checkpoint, the shape in current model is torch.Size([51, 160, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.2.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([51]).\n",
            "unexpected key in source state_dict: backbone.stem.bn.weight, backbone.stem.bn.bias, backbone.stem.bn.running_mean, backbone.stem.bn.running_var, backbone.stem.bn.num_batches_tracked, backbone.stem.conv.weight, backbone.stage1.0.bn.weight, backbone.stage1.0.bn.bias, backbone.stage1.0.bn.running_mean, backbone.stage1.0.bn.running_var, backbone.stage1.0.bn.num_batches_tracked, backbone.stage1.0.conv.weight, backbone.stage1.1.main_conv.bn.weight, backbone.stage1.1.main_conv.bn.bias, backbone.stage1.1.main_conv.bn.running_mean, backbone.stage1.1.main_conv.bn.running_var, backbone.stage1.1.main_conv.bn.num_batches_tracked, backbone.stage1.1.short_conv.bn.weight, backbone.stage1.1.short_conv.bn.bias, backbone.stage1.1.short_conv.bn.running_mean, backbone.stage1.1.short_conv.bn.running_var, backbone.stage1.1.short_conv.bn.num_batches_tracked, backbone.stage1.1.final_conv.bn.weight, backbone.stage1.1.final_conv.bn.bias, backbone.stage1.1.final_conv.bn.running_mean, backbone.stage1.1.final_conv.bn.running_var, backbone.stage1.1.final_conv.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv1.bn.weight, backbone.stage1.1.blocks.0.conv1.bn.bias, backbone.stage1.1.blocks.0.conv1.bn.running_mean, backbone.stage1.1.blocks.0.conv1.bn.running_var, backbone.stage1.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv2.bn.weight, backbone.stage1.1.blocks.0.conv2.bn.bias, backbone.stage1.1.blocks.0.conv2.bn.running_mean, backbone.stage1.1.blocks.0.conv2.bn.running_var, backbone.stage1.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.0.bn.weight, backbone.stage2.0.bn.bias, backbone.stage2.0.bn.running_mean, backbone.stage2.0.bn.running_var, backbone.stage2.0.bn.num_batches_tracked, backbone.stage2.0.conv.weight, backbone.stage2.1.main_conv.bn.weight, backbone.stage2.1.main_conv.bn.bias, backbone.stage2.1.main_conv.bn.running_mean, backbone.stage2.1.main_conv.bn.running_var, backbone.stage2.1.main_conv.bn.num_batches_tracked, backbone.stage2.1.short_conv.bn.weight, backbone.stage2.1.short_conv.bn.bias, backbone.stage2.1.short_conv.bn.running_mean, backbone.stage2.1.short_conv.bn.running_var, backbone.stage2.1.short_conv.bn.num_batches_tracked, backbone.stage2.1.final_conv.bn.weight, backbone.stage2.1.final_conv.bn.bias, backbone.stage2.1.final_conv.bn.running_mean, backbone.stage2.1.final_conv.bn.running_var, backbone.stage2.1.final_conv.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv1.bn.weight, backbone.stage2.1.blocks.0.conv1.bn.bias, backbone.stage2.1.blocks.0.conv1.bn.running_mean, backbone.stage2.1.blocks.0.conv1.bn.running_var, backbone.stage2.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv2.bn.weight, backbone.stage2.1.blocks.0.conv2.bn.bias, backbone.stage2.1.blocks.0.conv2.bn.running_mean, backbone.stage2.1.blocks.0.conv2.bn.running_var, backbone.stage2.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv1.bn.weight, backbone.stage2.1.blocks.1.conv1.bn.bias, backbone.stage2.1.blocks.1.conv1.bn.running_mean, backbone.stage2.1.blocks.1.conv1.bn.running_var, backbone.stage2.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv2.bn.weight, backbone.stage2.1.blocks.1.conv2.bn.bias, backbone.stage2.1.blocks.1.conv2.bn.running_mean, backbone.stage2.1.blocks.1.conv2.bn.running_var, backbone.stage2.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.0.bn.weight, backbone.stage3.0.bn.bias, backbone.stage3.0.bn.running_mean, backbone.stage3.0.bn.running_var, backbone.stage3.0.bn.num_batches_tracked, backbone.stage3.0.conv.weight, backbone.stage3.1.main_conv.bn.weight, backbone.stage3.1.main_conv.bn.bias, backbone.stage3.1.main_conv.bn.running_mean, backbone.stage3.1.main_conv.bn.running_var, backbone.stage3.1.main_conv.bn.num_batches_tracked, backbone.stage3.1.short_conv.bn.weight, backbone.stage3.1.short_conv.bn.bias, backbone.stage3.1.short_conv.bn.running_mean, backbone.stage3.1.short_conv.bn.running_var, backbone.stage3.1.short_conv.bn.num_batches_tracked, backbone.stage3.1.final_conv.bn.weight, backbone.stage3.1.final_conv.bn.bias, backbone.stage3.1.final_conv.bn.running_mean, backbone.stage3.1.final_conv.bn.running_var, backbone.stage3.1.final_conv.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv1.bn.weight, backbone.stage3.1.blocks.0.conv1.bn.bias, backbone.stage3.1.blocks.0.conv1.bn.running_mean, backbone.stage3.1.blocks.0.conv1.bn.running_var, backbone.stage3.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv2.bn.weight, backbone.stage3.1.blocks.0.conv2.bn.bias, backbone.stage3.1.blocks.0.conv2.bn.running_mean, backbone.stage3.1.blocks.0.conv2.bn.running_var, backbone.stage3.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv1.bn.weight, backbone.stage3.1.blocks.1.conv1.bn.bias, backbone.stage3.1.blocks.1.conv1.bn.running_mean, backbone.stage3.1.blocks.1.conv1.bn.running_var, backbone.stage3.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv2.bn.weight, backbone.stage3.1.blocks.1.conv2.bn.bias, backbone.stage3.1.blocks.1.conv2.bn.running_mean, backbone.stage3.1.blocks.1.conv2.bn.running_var, backbone.stage3.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv1.bn.weight, backbone.stage3.1.blocks.2.conv1.bn.bias, backbone.stage3.1.blocks.2.conv1.bn.running_mean, backbone.stage3.1.blocks.2.conv1.bn.running_var, backbone.stage3.1.blocks.2.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv2.bn.weight, backbone.stage3.1.blocks.2.conv2.bn.bias, backbone.stage3.1.blocks.2.conv2.bn.running_mean, backbone.stage3.1.blocks.2.conv2.bn.running_var, backbone.stage3.1.blocks.2.conv2.bn.num_batches_tracked, backbone.stage4.0.bn.weight, backbone.stage4.0.bn.bias, backbone.stage4.0.bn.running_mean, backbone.stage4.0.bn.running_var, backbone.stage4.0.bn.num_batches_tracked, backbone.stage4.0.conv.weight, backbone.stage4.1.main_conv.bn.weight, backbone.stage4.1.main_conv.bn.bias, backbone.stage4.1.main_conv.bn.running_mean, backbone.stage4.1.main_conv.bn.running_var, backbone.stage4.1.main_conv.bn.num_batches_tracked, backbone.stage4.1.short_conv.bn.weight, backbone.stage4.1.short_conv.bn.bias, backbone.stage4.1.short_conv.bn.running_mean, backbone.stage4.1.short_conv.bn.running_var, backbone.stage4.1.short_conv.bn.num_batches_tracked, backbone.stage4.1.final_conv.bn.weight, backbone.stage4.1.final_conv.bn.bias, backbone.stage4.1.final_conv.bn.running_mean, backbone.stage4.1.final_conv.bn.running_var, backbone.stage4.1.final_conv.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv1.bn.weight, backbone.stage4.1.blocks.0.conv1.bn.bias, backbone.stage4.1.blocks.0.conv1.bn.running_mean, backbone.stage4.1.blocks.0.conv1.bn.running_var, backbone.stage4.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv2.bn.weight, backbone.stage4.1.blocks.0.conv2.bn.bias, backbone.stage4.1.blocks.0.conv2.bn.running_mean, backbone.stage4.1.blocks.0.conv2.bn.running_var, backbone.stage4.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage4.2.conv1.bn.weight, backbone.stage4.2.conv1.bn.bias, backbone.stage4.2.conv1.bn.running_mean, backbone.stage4.2.conv1.bn.running_var, backbone.stage4.2.conv1.bn.num_batches_tracked, backbone.stage4.2.conv1.conv.weight, backbone.stage4.2.conv2.bn.weight, backbone.stage4.2.conv2.bn.bias, backbone.stage4.2.conv2.bn.running_mean, backbone.stage4.2.conv2.bn.running_var, backbone.stage4.2.conv2.bn.num_batches_tracked, backbone.stage4.2.conv2.conv.weight, neck.reduce_layers.2.bn.weight, neck.reduce_layers.2.bn.bias, neck.reduce_layers.2.bn.running_mean, neck.reduce_layers.2.bn.running_var, neck.reduce_layers.2.bn.num_batches_tracked, neck.reduce_layers.2.conv.weight, neck.top_down_layers.0.0.main_conv.bn.weight, neck.top_down_layers.0.0.main_conv.bn.bias, neck.top_down_layers.0.0.main_conv.bn.running_mean, neck.top_down_layers.0.0.main_conv.bn.running_var, neck.top_down_layers.0.0.main_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.short_conv.bn.weight, neck.top_down_layers.0.0.short_conv.bn.bias, neck.top_down_layers.0.0.short_conv.bn.running_mean, neck.top_down_layers.0.0.short_conv.bn.running_var, neck.top_down_layers.0.0.short_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.final_conv.bn.weight, neck.top_down_layers.0.0.final_conv.bn.bias, neck.top_down_layers.0.0.final_conv.bn.running_mean, neck.top_down_layers.0.0.final_conv.bn.running_var, neck.top_down_layers.0.0.final_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv1.bn.weight, neck.top_down_layers.0.0.blocks.0.conv1.bn.bias, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv2.bn.weight, neck.top_down_layers.0.0.blocks.0.conv2.bn.bias, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv2.bn.num_batches_tracked, neck.top_down_layers.0.1.bn.weight, neck.top_down_layers.0.1.bn.bias, neck.top_down_layers.0.1.bn.running_mean, neck.top_down_layers.0.1.bn.running_var, neck.top_down_layers.0.1.bn.num_batches_tracked, neck.top_down_layers.0.1.conv.weight, neck.top_down_layers.1.main_conv.bn.weight, neck.top_down_layers.1.main_conv.bn.bias, neck.top_down_layers.1.main_conv.bn.running_mean, neck.top_down_layers.1.main_conv.bn.running_var, neck.top_down_layers.1.main_conv.bn.num_batches_tracked, neck.top_down_layers.1.short_conv.bn.weight, neck.top_down_layers.1.short_conv.bn.bias, neck.top_down_layers.1.short_conv.bn.running_mean, neck.top_down_layers.1.short_conv.bn.running_var, neck.top_down_layers.1.short_conv.bn.num_batches_tracked, neck.top_down_layers.1.final_conv.bn.weight, neck.top_down_layers.1.final_conv.bn.bias, neck.top_down_layers.1.final_conv.bn.running_mean, neck.top_down_layers.1.final_conv.bn.running_var, neck.top_down_layers.1.final_conv.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv1.bn.weight, neck.top_down_layers.1.blocks.0.conv1.bn.bias, neck.top_down_layers.1.blocks.0.conv1.bn.running_mean, neck.top_down_layers.1.blocks.0.conv1.bn.running_var, neck.top_down_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv2.bn.weight, neck.top_down_layers.1.blocks.0.conv2.bn.bias, neck.top_down_layers.1.blocks.0.conv2.bn.running_mean, neck.top_down_layers.1.blocks.0.conv2.bn.running_var, neck.top_down_layers.1.blocks.0.conv2.bn.num_batches_tracked, neck.downsample_layers.0.bn.weight, neck.downsample_layers.0.bn.bias, neck.downsample_layers.0.bn.running_mean, neck.downsample_layers.0.bn.running_var, neck.downsample_layers.0.bn.num_batches_tracked, neck.downsample_layers.0.conv.weight, neck.downsample_layers.1.bn.weight, neck.downsample_layers.1.bn.bias, neck.downsample_layers.1.bn.running_mean, neck.downsample_layers.1.bn.running_var, neck.downsample_layers.1.bn.num_batches_tracked, neck.downsample_layers.1.conv.weight, neck.bottom_up_layers.0.main_conv.bn.weight, neck.bottom_up_layers.0.main_conv.bn.bias, neck.bottom_up_layers.0.main_conv.bn.running_mean, neck.bottom_up_layers.0.main_conv.bn.running_var, neck.bottom_up_layers.0.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.short_conv.bn.weight, neck.bottom_up_layers.0.short_conv.bn.bias, neck.bottom_up_layers.0.short_conv.bn.running_mean, neck.bottom_up_layers.0.short_conv.bn.running_var, neck.bottom_up_layers.0.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.final_conv.bn.weight, neck.bottom_up_layers.0.final_conv.bn.bias, neck.bottom_up_layers.0.final_conv.bn.running_mean, neck.bottom_up_layers.0.final_conv.bn.running_var, neck.bottom_up_layers.0.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv1.bn.weight, neck.bottom_up_layers.0.blocks.0.conv1.bn.bias, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv2.bn.weight, neck.bottom_up_layers.0.blocks.0.conv2.bn.bias, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv2.bn.num_batches_tracked, neck.bottom_up_layers.1.main_conv.bn.weight, neck.bottom_up_layers.1.main_conv.bn.bias, neck.bottom_up_layers.1.main_conv.bn.running_mean, neck.bottom_up_layers.1.main_conv.bn.running_var, neck.bottom_up_layers.1.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.short_conv.bn.weight, neck.bottom_up_layers.1.short_conv.bn.bias, neck.bottom_up_layers.1.short_conv.bn.running_mean, neck.bottom_up_layers.1.short_conv.bn.running_var, neck.bottom_up_layers.1.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.final_conv.bn.weight, neck.bottom_up_layers.1.final_conv.bn.bias, neck.bottom_up_layers.1.final_conv.bn.running_mean, neck.bottom_up_layers.1.final_conv.bn.running_var, neck.bottom_up_layers.1.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv1.bn.weight, neck.bottom_up_layers.1.blocks.0.conv1.bn.bias, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv2.bn.weight, neck.bottom_up_layers.1.blocks.0.conv2.bn.bias, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv2.bn.num_batches_tracked\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.conv.conv.weight, backbone.stem.conv.norm.weight, backbone.stem.conv.norm.bias, backbone.stem.conv.norm.running_mean, backbone.stem.conv.norm.running_var, backbone.stage1.0.conv.conv.weight, backbone.stage1.0.conv.norm.weight, backbone.stage1.0.conv.norm.bias, backbone.stage1.0.conv.norm.running_mean, backbone.stage1.0.conv.norm.running_var, backbone.stage1.1.main_conv.norm.weight, backbone.stage1.1.main_conv.norm.bias, backbone.stage1.1.main_conv.norm.running_mean, backbone.stage1.1.main_conv.norm.running_var, backbone.stage1.1.short_conv.norm.weight, backbone.stage1.1.short_conv.norm.bias, backbone.stage1.1.short_conv.norm.running_mean, backbone.stage1.1.short_conv.norm.running_var, backbone.stage1.1.final_conv.norm.weight, backbone.stage1.1.final_conv.norm.bias, backbone.stage1.1.final_conv.norm.running_mean, backbone.stage1.1.final_conv.norm.running_var, backbone.stage1.1.blocks.0.conv1.norm.weight, backbone.stage1.1.blocks.0.conv1.norm.bias, backbone.stage1.1.blocks.0.conv1.norm.running_mean, backbone.stage1.1.blocks.0.conv1.norm.running_var, backbone.stage1.1.blocks.0.conv2.norm.weight, backbone.stage1.1.blocks.0.conv2.norm.bias, backbone.stage1.1.blocks.0.conv2.norm.running_mean, backbone.stage1.1.blocks.0.conv2.norm.running_var, backbone.stage1.1.blocks.1.conv1.conv.weight, backbone.stage1.1.blocks.1.conv1.norm.weight, backbone.stage1.1.blocks.1.conv1.norm.bias, backbone.stage1.1.blocks.1.conv1.norm.running_mean, backbone.stage1.1.blocks.1.conv1.norm.running_var, backbone.stage1.1.blocks.1.conv2.conv.weight, backbone.stage1.1.blocks.1.conv2.norm.weight, backbone.stage1.1.blocks.1.conv2.norm.bias, backbone.stage1.1.blocks.1.conv2.norm.running_mean, backbone.stage1.1.blocks.1.conv2.norm.running_var, backbone.stage1.1.blocks.2.conv1.conv.weight, backbone.stage1.1.blocks.2.conv1.norm.weight, backbone.stage1.1.blocks.2.conv1.norm.bias, backbone.stage1.1.blocks.2.conv1.norm.running_mean, backbone.stage1.1.blocks.2.conv1.norm.running_var, backbone.stage1.1.blocks.2.conv2.conv.weight, backbone.stage1.1.blocks.2.conv2.norm.weight, backbone.stage1.1.blocks.2.conv2.norm.bias, backbone.stage1.1.blocks.2.conv2.norm.running_mean, backbone.stage1.1.blocks.2.conv2.norm.running_var, backbone.stage2.0.conv.conv.weight, backbone.stage2.0.conv.norm.weight, backbone.stage2.0.conv.norm.bias, backbone.stage2.0.conv.norm.running_mean, backbone.stage2.0.conv.norm.running_var, backbone.stage2.1.main_conv.norm.weight, backbone.stage2.1.main_conv.norm.bias, backbone.stage2.1.main_conv.norm.running_mean, backbone.stage2.1.main_conv.norm.running_var, backbone.stage2.1.short_conv.norm.weight, backbone.stage2.1.short_conv.norm.bias, backbone.stage2.1.short_conv.norm.running_mean, backbone.stage2.1.short_conv.norm.running_var, backbone.stage2.1.final_conv.norm.weight, backbone.stage2.1.final_conv.norm.bias, backbone.stage2.1.final_conv.norm.running_mean, backbone.stage2.1.final_conv.norm.running_var, backbone.stage2.1.blocks.0.conv1.norm.weight, backbone.stage2.1.blocks.0.conv1.norm.bias, backbone.stage2.1.blocks.0.conv1.norm.running_mean, backbone.stage2.1.blocks.0.conv1.norm.running_var, backbone.stage2.1.blocks.0.conv2.norm.weight, backbone.stage2.1.blocks.0.conv2.norm.bias, backbone.stage2.1.blocks.0.conv2.norm.running_mean, backbone.stage2.1.blocks.0.conv2.norm.running_var, backbone.stage2.1.blocks.1.conv1.norm.weight, backbone.stage2.1.blocks.1.conv1.norm.bias, backbone.stage2.1.blocks.1.conv1.norm.running_mean, backbone.stage2.1.blocks.1.conv1.norm.running_var, backbone.stage2.1.blocks.1.conv2.norm.weight, backbone.stage2.1.blocks.1.conv2.norm.bias, backbone.stage2.1.blocks.1.conv2.norm.running_mean, backbone.stage2.1.blocks.1.conv2.norm.running_var, backbone.stage2.1.blocks.2.conv1.conv.weight, backbone.stage2.1.blocks.2.conv1.norm.weight, backbone.stage2.1.blocks.2.conv1.norm.bias, backbone.stage2.1.blocks.2.conv1.norm.running_mean, backbone.stage2.1.blocks.2.conv1.norm.running_var, backbone.stage2.1.blocks.2.conv2.conv.weight, backbone.stage2.1.blocks.2.conv2.norm.weight, backbone.stage2.1.blocks.2.conv2.norm.bias, backbone.stage2.1.blocks.2.conv2.norm.running_mean, backbone.stage2.1.blocks.2.conv2.norm.running_var, backbone.stage2.1.blocks.3.conv1.conv.weight, backbone.stage2.1.blocks.3.conv1.norm.weight, backbone.stage2.1.blocks.3.conv1.norm.bias, backbone.stage2.1.blocks.3.conv1.norm.running_mean, backbone.stage2.1.blocks.3.conv1.norm.running_var, backbone.stage2.1.blocks.3.conv2.conv.weight, backbone.stage2.1.blocks.3.conv2.norm.weight, backbone.stage2.1.blocks.3.conv2.norm.bias, backbone.stage2.1.blocks.3.conv2.norm.running_mean, backbone.stage2.1.blocks.3.conv2.norm.running_var, backbone.stage2.1.blocks.4.conv1.conv.weight, backbone.stage2.1.blocks.4.conv1.norm.weight, backbone.stage2.1.blocks.4.conv1.norm.bias, backbone.stage2.1.blocks.4.conv1.norm.running_mean, backbone.stage2.1.blocks.4.conv1.norm.running_var, backbone.stage2.1.blocks.4.conv2.conv.weight, backbone.stage2.1.blocks.4.conv2.norm.weight, backbone.stage2.1.blocks.4.conv2.norm.bias, backbone.stage2.1.blocks.4.conv2.norm.running_mean, backbone.stage2.1.blocks.4.conv2.norm.running_var, backbone.stage2.1.blocks.5.conv1.conv.weight, backbone.stage2.1.blocks.5.conv1.norm.weight, backbone.stage2.1.blocks.5.conv1.norm.bias, backbone.stage2.1.blocks.5.conv1.norm.running_mean, backbone.stage2.1.blocks.5.conv1.norm.running_var, backbone.stage2.1.blocks.5.conv2.conv.weight, backbone.stage2.1.blocks.5.conv2.norm.weight, backbone.stage2.1.blocks.5.conv2.norm.bias, backbone.stage2.1.blocks.5.conv2.norm.running_mean, backbone.stage2.1.blocks.5.conv2.norm.running_var, backbone.stage3.0.conv.conv.weight, backbone.stage3.0.conv.norm.weight, backbone.stage3.0.conv.norm.bias, backbone.stage3.0.conv.norm.running_mean, backbone.stage3.0.conv.norm.running_var, backbone.stage3.1.main_conv.norm.weight, backbone.stage3.1.main_conv.norm.bias, backbone.stage3.1.main_conv.norm.running_mean, backbone.stage3.1.main_conv.norm.running_var, backbone.stage3.1.short_conv.norm.weight, backbone.stage3.1.short_conv.norm.bias, backbone.stage3.1.short_conv.norm.running_mean, backbone.stage3.1.short_conv.norm.running_var, backbone.stage3.1.final_conv.norm.weight, backbone.stage3.1.final_conv.norm.bias, backbone.stage3.1.final_conv.norm.running_mean, backbone.stage3.1.final_conv.norm.running_var, backbone.stage3.1.blocks.0.conv1.norm.weight, backbone.stage3.1.blocks.0.conv1.norm.bias, backbone.stage3.1.blocks.0.conv1.norm.running_mean, backbone.stage3.1.blocks.0.conv1.norm.running_var, backbone.stage3.1.blocks.0.conv2.norm.weight, backbone.stage3.1.blocks.0.conv2.norm.bias, backbone.stage3.1.blocks.0.conv2.norm.running_mean, backbone.stage3.1.blocks.0.conv2.norm.running_var, backbone.stage3.1.blocks.1.conv1.norm.weight, backbone.stage3.1.blocks.1.conv1.norm.bias, backbone.stage3.1.blocks.1.conv1.norm.running_mean, backbone.stage3.1.blocks.1.conv1.norm.running_var, backbone.stage3.1.blocks.1.conv2.norm.weight, backbone.stage3.1.blocks.1.conv2.norm.bias, backbone.stage3.1.blocks.1.conv2.norm.running_mean, backbone.stage3.1.blocks.1.conv2.norm.running_var, backbone.stage3.1.blocks.2.conv1.norm.weight, backbone.stage3.1.blocks.2.conv1.norm.bias, backbone.stage3.1.blocks.2.conv1.norm.running_mean, backbone.stage3.1.blocks.2.conv1.norm.running_var, backbone.stage3.1.blocks.2.conv2.norm.weight, backbone.stage3.1.blocks.2.conv2.norm.bias, backbone.stage3.1.blocks.2.conv2.norm.running_mean, backbone.stage3.1.blocks.2.conv2.norm.running_var, backbone.stage3.1.blocks.3.conv1.conv.weight, backbone.stage3.1.blocks.3.conv1.norm.weight, backbone.stage3.1.blocks.3.conv1.norm.bias, backbone.stage3.1.blocks.3.conv1.norm.running_mean, backbone.stage3.1.blocks.3.conv1.norm.running_var, backbone.stage3.1.blocks.3.conv2.conv.weight, backbone.stage3.1.blocks.3.conv2.norm.weight, backbone.stage3.1.blocks.3.conv2.norm.bias, backbone.stage3.1.blocks.3.conv2.norm.running_mean, backbone.stage3.1.blocks.3.conv2.norm.running_var, backbone.stage3.1.blocks.4.conv1.conv.weight, backbone.stage3.1.blocks.4.conv1.norm.weight, backbone.stage3.1.blocks.4.conv1.norm.bias, backbone.stage3.1.blocks.4.conv1.norm.running_mean, backbone.stage3.1.blocks.4.conv1.norm.running_var, backbone.stage3.1.blocks.4.conv2.conv.weight, backbone.stage3.1.blocks.4.conv2.norm.weight, backbone.stage3.1.blocks.4.conv2.norm.bias, backbone.stage3.1.blocks.4.conv2.norm.running_mean, backbone.stage3.1.blocks.4.conv2.norm.running_var, backbone.stage3.1.blocks.5.conv1.conv.weight, backbone.stage3.1.blocks.5.conv1.norm.weight, backbone.stage3.1.blocks.5.conv1.norm.bias, backbone.stage3.1.blocks.5.conv1.norm.running_mean, backbone.stage3.1.blocks.5.conv1.norm.running_var, backbone.stage3.1.blocks.5.conv2.conv.weight, backbone.stage3.1.blocks.5.conv2.norm.weight, backbone.stage3.1.blocks.5.conv2.norm.bias, backbone.stage3.1.blocks.5.conv2.norm.running_mean, backbone.stage3.1.blocks.5.conv2.norm.running_var, backbone.stage3.1.blocks.6.conv1.conv.weight, backbone.stage3.1.blocks.6.conv1.norm.weight, backbone.stage3.1.blocks.6.conv1.norm.bias, backbone.stage3.1.blocks.6.conv1.norm.running_mean, backbone.stage3.1.blocks.6.conv1.norm.running_var, backbone.stage3.1.blocks.6.conv2.conv.weight, backbone.stage3.1.blocks.6.conv2.norm.weight, backbone.stage3.1.blocks.6.conv2.norm.bias, backbone.stage3.1.blocks.6.conv2.norm.running_mean, backbone.stage3.1.blocks.6.conv2.norm.running_var, backbone.stage3.1.blocks.7.conv1.conv.weight, backbone.stage3.1.blocks.7.conv1.norm.weight, backbone.stage3.1.blocks.7.conv1.norm.bias, backbone.stage3.1.blocks.7.conv1.norm.running_mean, backbone.stage3.1.blocks.7.conv1.norm.running_var, backbone.stage3.1.blocks.7.conv2.conv.weight, backbone.stage3.1.blocks.7.conv2.norm.weight, backbone.stage3.1.blocks.7.conv2.norm.bias, backbone.stage3.1.blocks.7.conv2.norm.running_mean, backbone.stage3.1.blocks.7.conv2.norm.running_var, backbone.stage3.1.blocks.8.conv1.conv.weight, backbone.stage3.1.blocks.8.conv1.norm.weight, backbone.stage3.1.blocks.8.conv1.norm.bias, backbone.stage3.1.blocks.8.conv1.norm.running_mean, backbone.stage3.1.blocks.8.conv1.norm.running_var, backbone.stage3.1.blocks.8.conv2.conv.weight, backbone.stage3.1.blocks.8.conv2.norm.weight, backbone.stage3.1.blocks.8.conv2.norm.bias, backbone.stage3.1.blocks.8.conv2.norm.running_mean, backbone.stage3.1.blocks.8.conv2.norm.running_var, backbone.stage4.0.conv.conv.weight, backbone.stage4.0.conv.norm.weight, backbone.stage4.0.conv.norm.bias, backbone.stage4.0.conv.norm.running_mean, backbone.stage4.0.conv.norm.running_var, backbone.stage4.1.main_conv.norm.weight, backbone.stage4.1.main_conv.norm.bias, backbone.stage4.1.main_conv.norm.running_mean, backbone.stage4.1.main_conv.norm.running_var, backbone.stage4.1.short_conv.norm.weight, backbone.stage4.1.short_conv.norm.bias, backbone.stage4.1.short_conv.norm.running_mean, backbone.stage4.1.short_conv.norm.running_var, backbone.stage4.1.final_conv.norm.weight, backbone.stage4.1.final_conv.norm.bias, backbone.stage4.1.final_conv.norm.running_mean, backbone.stage4.1.final_conv.norm.running_var, backbone.stage4.1.blocks.0.conv1.norm.weight, backbone.stage4.1.blocks.0.conv1.norm.bias, backbone.stage4.1.blocks.0.conv1.norm.running_mean, backbone.stage4.1.blocks.0.conv1.norm.running_var, backbone.stage4.1.blocks.0.conv2.norm.weight, backbone.stage4.1.blocks.0.conv2.norm.bias, backbone.stage4.1.blocks.0.conv2.norm.running_mean, backbone.stage4.1.blocks.0.conv2.norm.running_var, backbone.stage4.1.blocks.1.conv1.conv.weight, backbone.stage4.1.blocks.1.conv1.norm.weight, backbone.stage4.1.blocks.1.conv1.norm.bias, backbone.stage4.1.blocks.1.conv1.norm.running_mean, backbone.stage4.1.blocks.1.conv1.norm.running_var, backbone.stage4.1.blocks.1.conv2.conv.weight, backbone.stage4.1.blocks.1.conv2.norm.weight, backbone.stage4.1.blocks.1.conv2.norm.bias, backbone.stage4.1.blocks.1.conv2.norm.running_mean, backbone.stage4.1.blocks.1.conv2.norm.running_var, backbone.stage4.1.blocks.2.conv1.conv.weight, backbone.stage4.1.blocks.2.conv1.norm.weight, backbone.stage4.1.blocks.2.conv1.norm.bias, backbone.stage4.1.blocks.2.conv1.norm.running_mean, backbone.stage4.1.blocks.2.conv1.norm.running_var, backbone.stage4.1.blocks.2.conv2.conv.weight, backbone.stage4.1.blocks.2.conv2.norm.weight, backbone.stage4.1.blocks.2.conv2.norm.bias, backbone.stage4.1.blocks.2.conv2.norm.running_mean, backbone.stage4.1.blocks.2.conv2.norm.running_var, backbone.stage4.2.conv1.conv.conv.weight, backbone.stage4.2.conv1.conv.norm.weight, backbone.stage4.2.conv1.conv.norm.bias, backbone.stage4.2.conv1.conv.norm.running_mean, backbone.stage4.2.conv1.conv.norm.running_var, backbone.stage4.2.conv2.conv.conv.weight, backbone.stage4.2.conv2.conv.norm.weight, backbone.stage4.2.conv2.conv.norm.bias, backbone.stage4.2.conv2.conv.norm.running_mean, backbone.stage4.2.conv2.conv.norm.running_var, neck.reduce_layers.2.conv.conv.weight, neck.reduce_layers.2.conv.norm.weight, neck.reduce_layers.2.conv.norm.bias, neck.reduce_layers.2.conv.norm.running_mean, neck.reduce_layers.2.conv.norm.running_var, neck.top_down_layers.0.0.main_conv.norm.weight, neck.top_down_layers.0.0.main_conv.norm.bias, neck.top_down_layers.0.0.main_conv.norm.running_mean, neck.top_down_layers.0.0.main_conv.norm.running_var, neck.top_down_layers.0.0.short_conv.norm.weight, neck.top_down_layers.0.0.short_conv.norm.bias, neck.top_down_layers.0.0.short_conv.norm.running_mean, neck.top_down_layers.0.0.short_conv.norm.running_var, neck.top_down_layers.0.0.final_conv.norm.weight, neck.top_down_layers.0.0.final_conv.norm.bias, neck.top_down_layers.0.0.final_conv.norm.running_mean, neck.top_down_layers.0.0.final_conv.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv1.norm.weight, neck.top_down_layers.0.0.blocks.0.conv1.norm.bias, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv2.norm.weight, neck.top_down_layers.0.0.blocks.0.conv2.norm.bias, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_var, neck.top_down_layers.0.1.conv.conv.weight, neck.top_down_layers.0.1.conv.norm.weight, neck.top_down_layers.0.1.conv.norm.bias, neck.top_down_layers.0.1.conv.norm.running_mean, neck.top_down_layers.0.1.conv.norm.running_var, neck.top_down_layers.1.main_conv.norm.weight, neck.top_down_layers.1.main_conv.norm.bias, neck.top_down_layers.1.main_conv.norm.running_mean, neck.top_down_layers.1.main_conv.norm.running_var, neck.top_down_layers.1.short_conv.norm.weight, neck.top_down_layers.1.short_conv.norm.bias, neck.top_down_layers.1.short_conv.norm.running_mean, neck.top_down_layers.1.short_conv.norm.running_var, neck.top_down_layers.1.final_conv.norm.weight, neck.top_down_layers.1.final_conv.norm.bias, neck.top_down_layers.1.final_conv.norm.running_mean, neck.top_down_layers.1.final_conv.norm.running_var, neck.top_down_layers.1.blocks.0.conv1.norm.weight, neck.top_down_layers.1.blocks.0.conv1.norm.bias, neck.top_down_layers.1.blocks.0.conv1.norm.running_mean, neck.top_down_layers.1.blocks.0.conv1.norm.running_var, neck.top_down_layers.1.blocks.0.conv2.norm.weight, neck.top_down_layers.1.blocks.0.conv2.norm.bias, neck.top_down_layers.1.blocks.0.conv2.norm.running_mean, neck.top_down_layers.1.blocks.0.conv2.norm.running_var, neck.downsample_layers.0.conv.conv.weight, neck.downsample_layers.0.conv.norm.weight, neck.downsample_layers.0.conv.norm.bias, neck.downsample_layers.0.conv.norm.running_mean, neck.downsample_layers.0.conv.norm.running_var, neck.downsample_layers.1.conv.conv.weight, neck.downsample_layers.1.conv.norm.weight, neck.downsample_layers.1.conv.norm.bias, neck.downsample_layers.1.conv.norm.running_mean, neck.downsample_layers.1.conv.norm.running_var, neck.bottom_up_layers.0.main_conv.norm.weight, neck.bottom_up_layers.0.main_conv.norm.bias, neck.bottom_up_layers.0.main_conv.norm.running_mean, neck.bottom_up_layers.0.main_conv.norm.running_var, neck.bottom_up_layers.0.short_conv.norm.weight, neck.bottom_up_layers.0.short_conv.norm.bias, neck.bottom_up_layers.0.short_conv.norm.running_mean, neck.bottom_up_layers.0.short_conv.norm.running_var, neck.bottom_up_layers.0.final_conv.norm.weight, neck.bottom_up_layers.0.final_conv.norm.bias, neck.bottom_up_layers.0.final_conv.norm.running_mean, neck.bottom_up_layers.0.final_conv.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv1.norm.weight, neck.bottom_up_layers.0.blocks.0.conv1.norm.bias, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv2.norm.weight, neck.bottom_up_layers.0.blocks.0.conv2.norm.bias, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_var, neck.bottom_up_layers.1.main_conv.norm.weight, neck.bottom_up_layers.1.main_conv.norm.bias, neck.bottom_up_layers.1.main_conv.norm.running_mean, neck.bottom_up_layers.1.main_conv.norm.running_var, neck.bottom_up_layers.1.short_conv.norm.weight, neck.bottom_up_layers.1.short_conv.norm.bias, neck.bottom_up_layers.1.short_conv.norm.running_mean, neck.bottom_up_layers.1.short_conv.norm.running_var, neck.bottom_up_layers.1.final_conv.norm.weight, neck.bottom_up_layers.1.final_conv.norm.bias, neck.bottom_up_layers.1.final_conv.norm.running_mean, neck.bottom_up_layers.1.final_conv.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv1.norm.weight, neck.bottom_up_layers.1.blocks.0.conv1.norm.bias, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv2.norm.weight, neck.bottom_up_layers.1.blocks.0.conv2.norm.bias, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_var\n",
            "\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for bbox_head.head_module.convs_pred.0.weight: copying a param with shape torch.Size([24, 40, 1, 1]) from checkpoint, the shape in current model is torch.Size([51, 40, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.0.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([51]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.1.weight: copying a param with shape torch.Size([24, 80, 1, 1]) from checkpoint, the shape in current model is torch.Size([51, 80, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.1.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([51]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.2.weight: copying a param with shape torch.Size([24, 160, 1, 1]) from checkpoint, the shape in current model is torch.Size([51, 160, 1, 1]).\n",
            "size mismatch for bbox_head.head_module.convs_pred.2.bias: copying a param with shape torch.Size([24]) from checkpoint, the shape in current model is torch.Size([51]).\n",
            "unexpected key in source state_dict: backbone.stem.bn.weight, backbone.stem.bn.bias, backbone.stem.bn.running_mean, backbone.stem.bn.running_var, backbone.stem.bn.num_batches_tracked, backbone.stem.conv.weight, backbone.stage1.0.bn.weight, backbone.stage1.0.bn.bias, backbone.stage1.0.bn.running_mean, backbone.stage1.0.bn.running_var, backbone.stage1.0.bn.num_batches_tracked, backbone.stage1.0.conv.weight, backbone.stage1.1.main_conv.bn.weight, backbone.stage1.1.main_conv.bn.bias, backbone.stage1.1.main_conv.bn.running_mean, backbone.stage1.1.main_conv.bn.running_var, backbone.stage1.1.main_conv.bn.num_batches_tracked, backbone.stage1.1.short_conv.bn.weight, backbone.stage1.1.short_conv.bn.bias, backbone.stage1.1.short_conv.bn.running_mean, backbone.stage1.1.short_conv.bn.running_var, backbone.stage1.1.short_conv.bn.num_batches_tracked, backbone.stage1.1.final_conv.bn.weight, backbone.stage1.1.final_conv.bn.bias, backbone.stage1.1.final_conv.bn.running_mean, backbone.stage1.1.final_conv.bn.running_var, backbone.stage1.1.final_conv.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv1.bn.weight, backbone.stage1.1.blocks.0.conv1.bn.bias, backbone.stage1.1.blocks.0.conv1.bn.running_mean, backbone.stage1.1.blocks.0.conv1.bn.running_var, backbone.stage1.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv2.bn.weight, backbone.stage1.1.blocks.0.conv2.bn.bias, backbone.stage1.1.blocks.0.conv2.bn.running_mean, backbone.stage1.1.blocks.0.conv2.bn.running_var, backbone.stage1.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.0.bn.weight, backbone.stage2.0.bn.bias, backbone.stage2.0.bn.running_mean, backbone.stage2.0.bn.running_var, backbone.stage2.0.bn.num_batches_tracked, backbone.stage2.0.conv.weight, backbone.stage2.1.main_conv.bn.weight, backbone.stage2.1.main_conv.bn.bias, backbone.stage2.1.main_conv.bn.running_mean, backbone.stage2.1.main_conv.bn.running_var, backbone.stage2.1.main_conv.bn.num_batches_tracked, backbone.stage2.1.short_conv.bn.weight, backbone.stage2.1.short_conv.bn.bias, backbone.stage2.1.short_conv.bn.running_mean, backbone.stage2.1.short_conv.bn.running_var, backbone.stage2.1.short_conv.bn.num_batches_tracked, backbone.stage2.1.final_conv.bn.weight, backbone.stage2.1.final_conv.bn.bias, backbone.stage2.1.final_conv.bn.running_mean, backbone.stage2.1.final_conv.bn.running_var, backbone.stage2.1.final_conv.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv1.bn.weight, backbone.stage2.1.blocks.0.conv1.bn.bias, backbone.stage2.1.blocks.0.conv1.bn.running_mean, backbone.stage2.1.blocks.0.conv1.bn.running_var, backbone.stage2.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv2.bn.weight, backbone.stage2.1.blocks.0.conv2.bn.bias, backbone.stage2.1.blocks.0.conv2.bn.running_mean, backbone.stage2.1.blocks.0.conv2.bn.running_var, backbone.stage2.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv1.bn.weight, backbone.stage2.1.blocks.1.conv1.bn.bias, backbone.stage2.1.blocks.1.conv1.bn.running_mean, backbone.stage2.1.blocks.1.conv1.bn.running_var, backbone.stage2.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv2.bn.weight, backbone.stage2.1.blocks.1.conv2.bn.bias, backbone.stage2.1.blocks.1.conv2.bn.running_mean, backbone.stage2.1.blocks.1.conv2.bn.running_var, backbone.stage2.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.0.bn.weight, backbone.stage3.0.bn.bias, backbone.stage3.0.bn.running_mean, backbone.stage3.0.bn.running_var, backbone.stage3.0.bn.num_batches_tracked, backbone.stage3.0.conv.weight, backbone.stage3.1.main_conv.bn.weight, backbone.stage3.1.main_conv.bn.bias, backbone.stage3.1.main_conv.bn.running_mean, backbone.stage3.1.main_conv.bn.running_var, backbone.stage3.1.main_conv.bn.num_batches_tracked, backbone.stage3.1.short_conv.bn.weight, backbone.stage3.1.short_conv.bn.bias, backbone.stage3.1.short_conv.bn.running_mean, backbone.stage3.1.short_conv.bn.running_var, backbone.stage3.1.short_conv.bn.num_batches_tracked, backbone.stage3.1.final_conv.bn.weight, backbone.stage3.1.final_conv.bn.bias, backbone.stage3.1.final_conv.bn.running_mean, backbone.stage3.1.final_conv.bn.running_var, backbone.stage3.1.final_conv.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv1.bn.weight, backbone.stage3.1.blocks.0.conv1.bn.bias, backbone.stage3.1.blocks.0.conv1.bn.running_mean, backbone.stage3.1.blocks.0.conv1.bn.running_var, backbone.stage3.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv2.bn.weight, backbone.stage3.1.blocks.0.conv2.bn.bias, backbone.stage3.1.blocks.0.conv2.bn.running_mean, backbone.stage3.1.blocks.0.conv2.bn.running_var, backbone.stage3.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv1.bn.weight, backbone.stage3.1.blocks.1.conv1.bn.bias, backbone.stage3.1.blocks.1.conv1.bn.running_mean, backbone.stage3.1.blocks.1.conv1.bn.running_var, backbone.stage3.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv2.bn.weight, backbone.stage3.1.blocks.1.conv2.bn.bias, backbone.stage3.1.blocks.1.conv2.bn.running_mean, backbone.stage3.1.blocks.1.conv2.bn.running_var, backbone.stage3.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv1.bn.weight, backbone.stage3.1.blocks.2.conv1.bn.bias, backbone.stage3.1.blocks.2.conv1.bn.running_mean, backbone.stage3.1.blocks.2.conv1.bn.running_var, backbone.stage3.1.blocks.2.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv2.bn.weight, backbone.stage3.1.blocks.2.conv2.bn.bias, backbone.stage3.1.blocks.2.conv2.bn.running_mean, backbone.stage3.1.blocks.2.conv2.bn.running_var, backbone.stage3.1.blocks.2.conv2.bn.num_batches_tracked, backbone.stage4.0.bn.weight, backbone.stage4.0.bn.bias, backbone.stage4.0.bn.running_mean, backbone.stage4.0.bn.running_var, backbone.stage4.0.bn.num_batches_tracked, backbone.stage4.0.conv.weight, backbone.stage4.1.main_conv.bn.weight, backbone.stage4.1.main_conv.bn.bias, backbone.stage4.1.main_conv.bn.running_mean, backbone.stage4.1.main_conv.bn.running_var, backbone.stage4.1.main_conv.bn.num_batches_tracked, backbone.stage4.1.short_conv.bn.weight, backbone.stage4.1.short_conv.bn.bias, backbone.stage4.1.short_conv.bn.running_mean, backbone.stage4.1.short_conv.bn.running_var, backbone.stage4.1.short_conv.bn.num_batches_tracked, backbone.stage4.1.final_conv.bn.weight, backbone.stage4.1.final_conv.bn.bias, backbone.stage4.1.final_conv.bn.running_mean, backbone.stage4.1.final_conv.bn.running_var, backbone.stage4.1.final_conv.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv1.bn.weight, backbone.stage4.1.blocks.0.conv1.bn.bias, backbone.stage4.1.blocks.0.conv1.bn.running_mean, backbone.stage4.1.blocks.0.conv1.bn.running_var, backbone.stage4.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv2.bn.weight, backbone.stage4.1.blocks.0.conv2.bn.bias, backbone.stage4.1.blocks.0.conv2.bn.running_mean, backbone.stage4.1.blocks.0.conv2.bn.running_var, backbone.stage4.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage4.2.conv1.bn.weight, backbone.stage4.2.conv1.bn.bias, backbone.stage4.2.conv1.bn.running_mean, backbone.stage4.2.conv1.bn.running_var, backbone.stage4.2.conv1.bn.num_batches_tracked, backbone.stage4.2.conv1.conv.weight, backbone.stage4.2.conv2.bn.weight, backbone.stage4.2.conv2.bn.bias, backbone.stage4.2.conv2.bn.running_mean, backbone.stage4.2.conv2.bn.running_var, backbone.stage4.2.conv2.bn.num_batches_tracked, backbone.stage4.2.conv2.conv.weight, neck.reduce_layers.2.bn.weight, neck.reduce_layers.2.bn.bias, neck.reduce_layers.2.bn.running_mean, neck.reduce_layers.2.bn.running_var, neck.reduce_layers.2.bn.num_batches_tracked, neck.reduce_layers.2.conv.weight, neck.top_down_layers.0.0.main_conv.bn.weight, neck.top_down_layers.0.0.main_conv.bn.bias, neck.top_down_layers.0.0.main_conv.bn.running_mean, neck.top_down_layers.0.0.main_conv.bn.running_var, neck.top_down_layers.0.0.main_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.short_conv.bn.weight, neck.top_down_layers.0.0.short_conv.bn.bias, neck.top_down_layers.0.0.short_conv.bn.running_mean, neck.top_down_layers.0.0.short_conv.bn.running_var, neck.top_down_layers.0.0.short_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.final_conv.bn.weight, neck.top_down_layers.0.0.final_conv.bn.bias, neck.top_down_layers.0.0.final_conv.bn.running_mean, neck.top_down_layers.0.0.final_conv.bn.running_var, neck.top_down_layers.0.0.final_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv1.bn.weight, neck.top_down_layers.0.0.blocks.0.conv1.bn.bias, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv2.bn.weight, neck.top_down_layers.0.0.blocks.0.conv2.bn.bias, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv2.bn.num_batches_tracked, neck.top_down_layers.0.1.bn.weight, neck.top_down_layers.0.1.bn.bias, neck.top_down_layers.0.1.bn.running_mean, neck.top_down_layers.0.1.bn.running_var, neck.top_down_layers.0.1.bn.num_batches_tracked, neck.top_down_layers.0.1.conv.weight, neck.top_down_layers.1.main_conv.bn.weight, neck.top_down_layers.1.main_conv.bn.bias, neck.top_down_layers.1.main_conv.bn.running_mean, neck.top_down_layers.1.main_conv.bn.running_var, neck.top_down_layers.1.main_conv.bn.num_batches_tracked, neck.top_down_layers.1.short_conv.bn.weight, neck.top_down_layers.1.short_conv.bn.bias, neck.top_down_layers.1.short_conv.bn.running_mean, neck.top_down_layers.1.short_conv.bn.running_var, neck.top_down_layers.1.short_conv.bn.num_batches_tracked, neck.top_down_layers.1.final_conv.bn.weight, neck.top_down_layers.1.final_conv.bn.bias, neck.top_down_layers.1.final_conv.bn.running_mean, neck.top_down_layers.1.final_conv.bn.running_var, neck.top_down_layers.1.final_conv.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv1.bn.weight, neck.top_down_layers.1.blocks.0.conv1.bn.bias, neck.top_down_layers.1.blocks.0.conv1.bn.running_mean, neck.top_down_layers.1.blocks.0.conv1.bn.running_var, neck.top_down_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv2.bn.weight, neck.top_down_layers.1.blocks.0.conv2.bn.bias, neck.top_down_layers.1.blocks.0.conv2.bn.running_mean, neck.top_down_layers.1.blocks.0.conv2.bn.running_var, neck.top_down_layers.1.blocks.0.conv2.bn.num_batches_tracked, neck.downsample_layers.0.bn.weight, neck.downsample_layers.0.bn.bias, neck.downsample_layers.0.bn.running_mean, neck.downsample_layers.0.bn.running_var, neck.downsample_layers.0.bn.num_batches_tracked, neck.downsample_layers.0.conv.weight, neck.downsample_layers.1.bn.weight, neck.downsample_layers.1.bn.bias, neck.downsample_layers.1.bn.running_mean, neck.downsample_layers.1.bn.running_var, neck.downsample_layers.1.bn.num_batches_tracked, neck.downsample_layers.1.conv.weight, neck.bottom_up_layers.0.main_conv.bn.weight, neck.bottom_up_layers.0.main_conv.bn.bias, neck.bottom_up_layers.0.main_conv.bn.running_mean, neck.bottom_up_layers.0.main_conv.bn.running_var, neck.bottom_up_layers.0.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.short_conv.bn.weight, neck.bottom_up_layers.0.short_conv.bn.bias, neck.bottom_up_layers.0.short_conv.bn.running_mean, neck.bottom_up_layers.0.short_conv.bn.running_var, neck.bottom_up_layers.0.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.final_conv.bn.weight, neck.bottom_up_layers.0.final_conv.bn.bias, neck.bottom_up_layers.0.final_conv.bn.running_mean, neck.bottom_up_layers.0.final_conv.bn.running_var, neck.bottom_up_layers.0.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv1.bn.weight, neck.bottom_up_layers.0.blocks.0.conv1.bn.bias, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv2.bn.weight, neck.bottom_up_layers.0.blocks.0.conv2.bn.bias, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv2.bn.num_batches_tracked, neck.bottom_up_layers.1.main_conv.bn.weight, neck.bottom_up_layers.1.main_conv.bn.bias, neck.bottom_up_layers.1.main_conv.bn.running_mean, neck.bottom_up_layers.1.main_conv.bn.running_var, neck.bottom_up_layers.1.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.short_conv.bn.weight, neck.bottom_up_layers.1.short_conv.bn.bias, neck.bottom_up_layers.1.short_conv.bn.running_mean, neck.bottom_up_layers.1.short_conv.bn.running_var, neck.bottom_up_layers.1.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.final_conv.bn.weight, neck.bottom_up_layers.1.final_conv.bn.bias, neck.bottom_up_layers.1.final_conv.bn.running_mean, neck.bottom_up_layers.1.final_conv.bn.running_var, neck.bottom_up_layers.1.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv1.bn.weight, neck.bottom_up_layers.1.blocks.0.conv1.bn.bias, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv2.bn.weight, neck.bottom_up_layers.1.blocks.0.conv2.bn.bias, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv2.bn.num_batches_tracked\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.conv.conv.weight, backbone.stem.conv.norm.weight, backbone.stem.conv.norm.bias, backbone.stem.conv.norm.running_mean, backbone.stem.conv.norm.running_var, backbone.stage1.0.conv.conv.weight, backbone.stage1.0.conv.norm.weight, backbone.stage1.0.conv.norm.bias, backbone.stage1.0.conv.norm.running_mean, backbone.stage1.0.conv.norm.running_var, backbone.stage1.1.main_conv.norm.weight, backbone.stage1.1.main_conv.norm.bias, backbone.stage1.1.main_conv.norm.running_mean, backbone.stage1.1.main_conv.norm.running_var, backbone.stage1.1.short_conv.norm.weight, backbone.stage1.1.short_conv.norm.bias, backbone.stage1.1.short_conv.norm.running_mean, backbone.stage1.1.short_conv.norm.running_var, backbone.stage1.1.final_conv.norm.weight, backbone.stage1.1.final_conv.norm.bias, backbone.stage1.1.final_conv.norm.running_mean, backbone.stage1.1.final_conv.norm.running_var, backbone.stage1.1.blocks.0.conv1.norm.weight, backbone.stage1.1.blocks.0.conv1.norm.bias, backbone.stage1.1.blocks.0.conv1.norm.running_mean, backbone.stage1.1.blocks.0.conv1.norm.running_var, backbone.stage1.1.blocks.0.conv2.norm.weight, backbone.stage1.1.blocks.0.conv2.norm.bias, backbone.stage1.1.blocks.0.conv2.norm.running_mean, backbone.stage1.1.blocks.0.conv2.norm.running_var, backbone.stage1.1.blocks.1.conv1.conv.weight, backbone.stage1.1.blocks.1.conv1.norm.weight, backbone.stage1.1.blocks.1.conv1.norm.bias, backbone.stage1.1.blocks.1.conv1.norm.running_mean, backbone.stage1.1.blocks.1.conv1.norm.running_var, backbone.stage1.1.blocks.1.conv2.conv.weight, backbone.stage1.1.blocks.1.conv2.norm.weight, backbone.stage1.1.blocks.1.conv2.norm.bias, backbone.stage1.1.blocks.1.conv2.norm.running_mean, backbone.stage1.1.blocks.1.conv2.norm.running_var, backbone.stage1.1.blocks.2.conv1.conv.weight, backbone.stage1.1.blocks.2.conv1.norm.weight, backbone.stage1.1.blocks.2.conv1.norm.bias, backbone.stage1.1.blocks.2.conv1.norm.running_mean, backbone.stage1.1.blocks.2.conv1.norm.running_var, backbone.stage1.1.blocks.2.conv2.conv.weight, backbone.stage1.1.blocks.2.conv2.norm.weight, backbone.stage1.1.blocks.2.conv2.norm.bias, backbone.stage1.1.blocks.2.conv2.norm.running_mean, backbone.stage1.1.blocks.2.conv2.norm.running_var, backbone.stage2.0.conv.conv.weight, backbone.stage2.0.conv.norm.weight, backbone.stage2.0.conv.norm.bias, backbone.stage2.0.conv.norm.running_mean, backbone.stage2.0.conv.norm.running_var, backbone.stage2.1.main_conv.norm.weight, backbone.stage2.1.main_conv.norm.bias, backbone.stage2.1.main_conv.norm.running_mean, backbone.stage2.1.main_conv.norm.running_var, backbone.stage2.1.short_conv.norm.weight, backbone.stage2.1.short_conv.norm.bias, backbone.stage2.1.short_conv.norm.running_mean, backbone.stage2.1.short_conv.norm.running_var, backbone.stage2.1.final_conv.norm.weight, backbone.stage2.1.final_conv.norm.bias, backbone.stage2.1.final_conv.norm.running_mean, backbone.stage2.1.final_conv.norm.running_var, backbone.stage2.1.blocks.0.conv1.norm.weight, backbone.stage2.1.blocks.0.conv1.norm.bias, backbone.stage2.1.blocks.0.conv1.norm.running_mean, backbone.stage2.1.blocks.0.conv1.norm.running_var, backbone.stage2.1.blocks.0.conv2.norm.weight, backbone.stage2.1.blocks.0.conv2.norm.bias, backbone.stage2.1.blocks.0.conv2.norm.running_mean, backbone.stage2.1.blocks.0.conv2.norm.running_var, backbone.stage2.1.blocks.1.conv1.norm.weight, backbone.stage2.1.blocks.1.conv1.norm.bias, backbone.stage2.1.blocks.1.conv1.norm.running_mean, backbone.stage2.1.blocks.1.conv1.norm.running_var, backbone.stage2.1.blocks.1.conv2.norm.weight, backbone.stage2.1.blocks.1.conv2.norm.bias, backbone.stage2.1.blocks.1.conv2.norm.running_mean, backbone.stage2.1.blocks.1.conv2.norm.running_var, backbone.stage2.1.blocks.2.conv1.conv.weight, backbone.stage2.1.blocks.2.conv1.norm.weight, backbone.stage2.1.blocks.2.conv1.norm.bias, backbone.stage2.1.blocks.2.conv1.norm.running_mean, backbone.stage2.1.blocks.2.conv1.norm.running_var, backbone.stage2.1.blocks.2.conv2.conv.weight, backbone.stage2.1.blocks.2.conv2.norm.weight, backbone.stage2.1.blocks.2.conv2.norm.bias, backbone.stage2.1.blocks.2.conv2.norm.running_mean, backbone.stage2.1.blocks.2.conv2.norm.running_var, backbone.stage2.1.blocks.3.conv1.conv.weight, backbone.stage2.1.blocks.3.conv1.norm.weight, backbone.stage2.1.blocks.3.conv1.norm.bias, backbone.stage2.1.blocks.3.conv1.norm.running_mean, backbone.stage2.1.blocks.3.conv1.norm.running_var, backbone.stage2.1.blocks.3.conv2.conv.weight, backbone.stage2.1.blocks.3.conv2.norm.weight, backbone.stage2.1.blocks.3.conv2.norm.bias, backbone.stage2.1.blocks.3.conv2.norm.running_mean, backbone.stage2.1.blocks.3.conv2.norm.running_var, backbone.stage2.1.blocks.4.conv1.conv.weight, backbone.stage2.1.blocks.4.conv1.norm.weight, backbone.stage2.1.blocks.4.conv1.norm.bias, backbone.stage2.1.blocks.4.conv1.norm.running_mean, backbone.stage2.1.blocks.4.conv1.norm.running_var, backbone.stage2.1.blocks.4.conv2.conv.weight, backbone.stage2.1.blocks.4.conv2.norm.weight, backbone.stage2.1.blocks.4.conv2.norm.bias, backbone.stage2.1.blocks.4.conv2.norm.running_mean, backbone.stage2.1.blocks.4.conv2.norm.running_var, backbone.stage2.1.blocks.5.conv1.conv.weight, backbone.stage2.1.blocks.5.conv1.norm.weight, backbone.stage2.1.blocks.5.conv1.norm.bias, backbone.stage2.1.blocks.5.conv1.norm.running_mean, backbone.stage2.1.blocks.5.conv1.norm.running_var, backbone.stage2.1.blocks.5.conv2.conv.weight, backbone.stage2.1.blocks.5.conv2.norm.weight, backbone.stage2.1.blocks.5.conv2.norm.bias, backbone.stage2.1.blocks.5.conv2.norm.running_mean, backbone.stage2.1.blocks.5.conv2.norm.running_var, backbone.stage3.0.conv.conv.weight, backbone.stage3.0.conv.norm.weight, backbone.stage3.0.conv.norm.bias, backbone.stage3.0.conv.norm.running_mean, backbone.stage3.0.conv.norm.running_var, backbone.stage3.1.main_conv.norm.weight, backbone.stage3.1.main_conv.norm.bias, backbone.stage3.1.main_conv.norm.running_mean, backbone.stage3.1.main_conv.norm.running_var, backbone.stage3.1.short_conv.norm.weight, backbone.stage3.1.short_conv.norm.bias, backbone.stage3.1.short_conv.norm.running_mean, backbone.stage3.1.short_conv.norm.running_var, backbone.stage3.1.final_conv.norm.weight, backbone.stage3.1.final_conv.norm.bias, backbone.stage3.1.final_conv.norm.running_mean, backbone.stage3.1.final_conv.norm.running_var, backbone.stage3.1.blocks.0.conv1.norm.weight, backbone.stage3.1.blocks.0.conv1.norm.bias, backbone.stage3.1.blocks.0.conv1.norm.running_mean, backbone.stage3.1.blocks.0.conv1.norm.running_var, backbone.stage3.1.blocks.0.conv2.norm.weight, backbone.stage3.1.blocks.0.conv2.norm.bias, backbone.stage3.1.blocks.0.conv2.norm.running_mean, backbone.stage3.1.blocks.0.conv2.norm.running_var, backbone.stage3.1.blocks.1.conv1.norm.weight, backbone.stage3.1.blocks.1.conv1.norm.bias, backbone.stage3.1.blocks.1.conv1.norm.running_mean, backbone.stage3.1.blocks.1.conv1.norm.running_var, backbone.stage3.1.blocks.1.conv2.norm.weight, backbone.stage3.1.blocks.1.conv2.norm.bias, backbone.stage3.1.blocks.1.conv2.norm.running_mean, backbone.stage3.1.blocks.1.conv2.norm.running_var, backbone.stage3.1.blocks.2.conv1.norm.weight, backbone.stage3.1.blocks.2.conv1.norm.bias, backbone.stage3.1.blocks.2.conv1.norm.running_mean, backbone.stage3.1.blocks.2.conv1.norm.running_var, backbone.stage3.1.blocks.2.conv2.norm.weight, backbone.stage3.1.blocks.2.conv2.norm.bias, backbone.stage3.1.blocks.2.conv2.norm.running_mean, backbone.stage3.1.blocks.2.conv2.norm.running_var, backbone.stage3.1.blocks.3.conv1.conv.weight, backbone.stage3.1.blocks.3.conv1.norm.weight, backbone.stage3.1.blocks.3.conv1.norm.bias, backbone.stage3.1.blocks.3.conv1.norm.running_mean, backbone.stage3.1.blocks.3.conv1.norm.running_var, backbone.stage3.1.blocks.3.conv2.conv.weight, backbone.stage3.1.blocks.3.conv2.norm.weight, backbone.stage3.1.blocks.3.conv2.norm.bias, backbone.stage3.1.blocks.3.conv2.norm.running_mean, backbone.stage3.1.blocks.3.conv2.norm.running_var, backbone.stage3.1.blocks.4.conv1.conv.weight, backbone.stage3.1.blocks.4.conv1.norm.weight, backbone.stage3.1.blocks.4.conv1.norm.bias, backbone.stage3.1.blocks.4.conv1.norm.running_mean, backbone.stage3.1.blocks.4.conv1.norm.running_var, backbone.stage3.1.blocks.4.conv2.conv.weight, backbone.stage3.1.blocks.4.conv2.norm.weight, backbone.stage3.1.blocks.4.conv2.norm.bias, backbone.stage3.1.blocks.4.conv2.norm.running_mean, backbone.stage3.1.blocks.4.conv2.norm.running_var, backbone.stage3.1.blocks.5.conv1.conv.weight, backbone.stage3.1.blocks.5.conv1.norm.weight, backbone.stage3.1.blocks.5.conv1.norm.bias, backbone.stage3.1.blocks.5.conv1.norm.running_mean, backbone.stage3.1.blocks.5.conv1.norm.running_var, backbone.stage3.1.blocks.5.conv2.conv.weight, backbone.stage3.1.blocks.5.conv2.norm.weight, backbone.stage3.1.blocks.5.conv2.norm.bias, backbone.stage3.1.blocks.5.conv2.norm.running_mean, backbone.stage3.1.blocks.5.conv2.norm.running_var, backbone.stage3.1.blocks.6.conv1.conv.weight, backbone.stage3.1.blocks.6.conv1.norm.weight, backbone.stage3.1.blocks.6.conv1.norm.bias, backbone.stage3.1.blocks.6.conv1.norm.running_mean, backbone.stage3.1.blocks.6.conv1.norm.running_var, backbone.stage3.1.blocks.6.conv2.conv.weight, backbone.stage3.1.blocks.6.conv2.norm.weight, backbone.stage3.1.blocks.6.conv2.norm.bias, backbone.stage3.1.blocks.6.conv2.norm.running_mean, backbone.stage3.1.blocks.6.conv2.norm.running_var, backbone.stage3.1.blocks.7.conv1.conv.weight, backbone.stage3.1.blocks.7.conv1.norm.weight, backbone.stage3.1.blocks.7.conv1.norm.bias, backbone.stage3.1.blocks.7.conv1.norm.running_mean, backbone.stage3.1.blocks.7.conv1.norm.running_var, backbone.stage3.1.blocks.7.conv2.conv.weight, backbone.stage3.1.blocks.7.conv2.norm.weight, backbone.stage3.1.blocks.7.conv2.norm.bias, backbone.stage3.1.blocks.7.conv2.norm.running_mean, backbone.stage3.1.blocks.7.conv2.norm.running_var, backbone.stage3.1.blocks.8.conv1.conv.weight, backbone.stage3.1.blocks.8.conv1.norm.weight, backbone.stage3.1.blocks.8.conv1.norm.bias, backbone.stage3.1.blocks.8.conv1.norm.running_mean, backbone.stage3.1.blocks.8.conv1.norm.running_var, backbone.stage3.1.blocks.8.conv2.conv.weight, backbone.stage3.1.blocks.8.conv2.norm.weight, backbone.stage3.1.blocks.8.conv2.norm.bias, backbone.stage3.1.blocks.8.conv2.norm.running_mean, backbone.stage3.1.blocks.8.conv2.norm.running_var, backbone.stage4.0.conv.conv.weight, backbone.stage4.0.conv.norm.weight, backbone.stage4.0.conv.norm.bias, backbone.stage4.0.conv.norm.running_mean, backbone.stage4.0.conv.norm.running_var, backbone.stage4.1.main_conv.norm.weight, backbone.stage4.1.main_conv.norm.bias, backbone.stage4.1.main_conv.norm.running_mean, backbone.stage4.1.main_conv.norm.running_var, backbone.stage4.1.short_conv.norm.weight, backbone.stage4.1.short_conv.norm.bias, backbone.stage4.1.short_conv.norm.running_mean, backbone.stage4.1.short_conv.norm.running_var, backbone.stage4.1.final_conv.norm.weight, backbone.stage4.1.final_conv.norm.bias, backbone.stage4.1.final_conv.norm.running_mean, backbone.stage4.1.final_conv.norm.running_var, backbone.stage4.1.blocks.0.conv1.norm.weight, backbone.stage4.1.blocks.0.conv1.norm.bias, backbone.stage4.1.blocks.0.conv1.norm.running_mean, backbone.stage4.1.blocks.0.conv1.norm.running_var, backbone.stage4.1.blocks.0.conv2.norm.weight, backbone.stage4.1.blocks.0.conv2.norm.bias, backbone.stage4.1.blocks.0.conv2.norm.running_mean, backbone.stage4.1.blocks.0.conv2.norm.running_var, backbone.stage4.1.blocks.1.conv1.conv.weight, backbone.stage4.1.blocks.1.conv1.norm.weight, backbone.stage4.1.blocks.1.conv1.norm.bias, backbone.stage4.1.blocks.1.conv1.norm.running_mean, backbone.stage4.1.blocks.1.conv1.norm.running_var, backbone.stage4.1.blocks.1.conv2.conv.weight, backbone.stage4.1.blocks.1.conv2.norm.weight, backbone.stage4.1.blocks.1.conv2.norm.bias, backbone.stage4.1.blocks.1.conv2.norm.running_mean, backbone.stage4.1.blocks.1.conv2.norm.running_var, backbone.stage4.1.blocks.2.conv1.conv.weight, backbone.stage4.1.blocks.2.conv1.norm.weight, backbone.stage4.1.blocks.2.conv1.norm.bias, backbone.stage4.1.blocks.2.conv1.norm.running_mean, backbone.stage4.1.blocks.2.conv1.norm.running_var, backbone.stage4.1.blocks.2.conv2.conv.weight, backbone.stage4.1.blocks.2.conv2.norm.weight, backbone.stage4.1.blocks.2.conv2.norm.bias, backbone.stage4.1.blocks.2.conv2.norm.running_mean, backbone.stage4.1.blocks.2.conv2.norm.running_var, backbone.stage4.2.conv1.conv.conv.weight, backbone.stage4.2.conv1.conv.norm.weight, backbone.stage4.2.conv1.conv.norm.bias, backbone.stage4.2.conv1.conv.norm.running_mean, backbone.stage4.2.conv1.conv.norm.running_var, backbone.stage4.2.conv2.conv.conv.weight, backbone.stage4.2.conv2.conv.norm.weight, backbone.stage4.2.conv2.conv.norm.bias, backbone.stage4.2.conv2.conv.norm.running_mean, backbone.stage4.2.conv2.conv.norm.running_var, neck.reduce_layers.2.conv.conv.weight, neck.reduce_layers.2.conv.norm.weight, neck.reduce_layers.2.conv.norm.bias, neck.reduce_layers.2.conv.norm.running_mean, neck.reduce_layers.2.conv.norm.running_var, neck.top_down_layers.0.0.main_conv.norm.weight, neck.top_down_layers.0.0.main_conv.norm.bias, neck.top_down_layers.0.0.main_conv.norm.running_mean, neck.top_down_layers.0.0.main_conv.norm.running_var, neck.top_down_layers.0.0.short_conv.norm.weight, neck.top_down_layers.0.0.short_conv.norm.bias, neck.top_down_layers.0.0.short_conv.norm.running_mean, neck.top_down_layers.0.0.short_conv.norm.running_var, neck.top_down_layers.0.0.final_conv.norm.weight, neck.top_down_layers.0.0.final_conv.norm.bias, neck.top_down_layers.0.0.final_conv.norm.running_mean, neck.top_down_layers.0.0.final_conv.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv1.norm.weight, neck.top_down_layers.0.0.blocks.0.conv1.norm.bias, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv2.norm.weight, neck.top_down_layers.0.0.blocks.0.conv2.norm.bias, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_var, neck.top_down_layers.0.1.conv.conv.weight, neck.top_down_layers.0.1.conv.norm.weight, neck.top_down_layers.0.1.conv.norm.bias, neck.top_down_layers.0.1.conv.norm.running_mean, neck.top_down_layers.0.1.conv.norm.running_var, neck.top_down_layers.1.main_conv.norm.weight, neck.top_down_layers.1.main_conv.norm.bias, neck.top_down_layers.1.main_conv.norm.running_mean, neck.top_down_layers.1.main_conv.norm.running_var, neck.top_down_layers.1.short_conv.norm.weight, neck.top_down_layers.1.short_conv.norm.bias, neck.top_down_layers.1.short_conv.norm.running_mean, neck.top_down_layers.1.short_conv.norm.running_var, neck.top_down_layers.1.final_conv.norm.weight, neck.top_down_layers.1.final_conv.norm.bias, neck.top_down_layers.1.final_conv.norm.running_mean, neck.top_down_layers.1.final_conv.norm.running_var, neck.top_down_layers.1.blocks.0.conv1.norm.weight, neck.top_down_layers.1.blocks.0.conv1.norm.bias, neck.top_down_layers.1.blocks.0.conv1.norm.running_mean, neck.top_down_layers.1.blocks.0.conv1.norm.running_var, neck.top_down_layers.1.blocks.0.conv2.norm.weight, neck.top_down_layers.1.blocks.0.conv2.norm.bias, neck.top_down_layers.1.blocks.0.conv2.norm.running_mean, neck.top_down_layers.1.blocks.0.conv2.norm.running_var, neck.downsample_layers.0.conv.conv.weight, neck.downsample_layers.0.conv.norm.weight, neck.downsample_layers.0.conv.norm.bias, neck.downsample_layers.0.conv.norm.running_mean, neck.downsample_layers.0.conv.norm.running_var, neck.downsample_layers.1.conv.conv.weight, neck.downsample_layers.1.conv.norm.weight, neck.downsample_layers.1.conv.norm.bias, neck.downsample_layers.1.conv.norm.running_mean, neck.downsample_layers.1.conv.norm.running_var, neck.bottom_up_layers.0.main_conv.norm.weight, neck.bottom_up_layers.0.main_conv.norm.bias, neck.bottom_up_layers.0.main_conv.norm.running_mean, neck.bottom_up_layers.0.main_conv.norm.running_var, neck.bottom_up_layers.0.short_conv.norm.weight, neck.bottom_up_layers.0.short_conv.norm.bias, neck.bottom_up_layers.0.short_conv.norm.running_mean, neck.bottom_up_layers.0.short_conv.norm.running_var, neck.bottom_up_layers.0.final_conv.norm.weight, neck.bottom_up_layers.0.final_conv.norm.bias, neck.bottom_up_layers.0.final_conv.norm.running_mean, neck.bottom_up_layers.0.final_conv.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv1.norm.weight, neck.bottom_up_layers.0.blocks.0.conv1.norm.bias, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv2.norm.weight, neck.bottom_up_layers.0.blocks.0.conv2.norm.bias, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_var, neck.bottom_up_layers.1.main_conv.norm.weight, neck.bottom_up_layers.1.main_conv.norm.bias, neck.bottom_up_layers.1.main_conv.norm.running_mean, neck.bottom_up_layers.1.main_conv.norm.running_var, neck.bottom_up_layers.1.short_conv.norm.weight, neck.bottom_up_layers.1.short_conv.norm.bias, neck.bottom_up_layers.1.short_conv.norm.running_mean, neck.bottom_up_layers.1.short_conv.norm.running_var, neck.bottom_up_layers.1.final_conv.norm.weight, neck.bottom_up_layers.1.final_conv.norm.bias, neck.bottom_up_layers.1.final_conv.norm.running_mean, neck.bottom_up_layers.1.final_conv.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv1.norm.weight, neck.bottom_up_layers.1.blocks.0.conv1.norm.bias, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv2.norm.weight, neck.bottom_up_layers.1.blocks.0.conv2.norm.bias, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_var\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      1/15     3.0452    0.9263    0.6271    1.4918   0:42:18  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:58<00:00,  3.92it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      2/15     2.8848    0.8647    0.6595    1.3606   0:39:05  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:59<00:00,  3.90it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      3/15     2.823     0.8523     0.7      1.2706   0:36:02  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:59<00:00,  3.90it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      4/15     2.6824    0.8463    0.6727    1.1634   0:32:52  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:56<00:00,  3.97it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      5/15     2.5812    0.8427    0.6522    1.0864   0:29:53  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:58<00:00,  3.91it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time      eta    \n",
            "   val       5/15     0.0196    0.1823   0:00:00  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:14<00:00,  6.79it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=1.69s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=9.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=4.94s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.093\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.022\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.247\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      6/15     2.4884    0.8201     0.64     1.0283   0:26:49  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:55<00:00,  3.97it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      7/15     2.4121    0.7853    0.6307    0.9961   0:23:50  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:58<00:00,  3.92it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      8/15     2.3514    0.7654    0.6197    0.9663   0:20:50  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:57<00:00,  3.94it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train      9/15     2.3013    0.7536    0.6122    0.9355   0:17:50  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:55<00:00,  3.97it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     10/15     2.2751    0.7453    0.6109    0.9189   0:14:51  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:57<00:00,  3.94it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      10/15     0.0056    0.1403    0.013     0.031     0.011      0.0      0.004     0.016    0:00:00  : 100%|â–ˆ| \n",
            "Loading and preparing results...\n",
            "DONE (t=1.46s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=10.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.66s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.040\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.049\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.266\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.372\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.416\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     11/15     2.2404    0.7407    0.6038    0.896    0:11:52  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:55<00:00,  3.99it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     12/15     2.2167    0.7334    0.6011    0.8822   0:08:54  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:57<00:00,  3.93it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     13/15     2.1973    0.7312    0.598     0.8681   0:05:56  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [03:01<00:00,  3.86it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     14/15     2.1669    0.7261    0.5848    0.856    0:02:58  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [02:57<00:00,  3.95it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     15/15     2.1604    0.7205    0.5919    0.848    0:00:00  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 699/699 [03:00<00:00,  3.86it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      15/15     0.0059    0.1416    0.042     0.085      0.04      0.0      0.004     0.049    0:00:00  : 100%|â–ˆ| \n",
            "Loading and preparing results...\n",
            "DONE (t=1.54s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=9.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=3.42s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.038\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.294\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457\n"
          ]
        }
      ],
      "source": [
        "!sscma.train configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=12 \\\n",
        "    epochs=15  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doAdzYYEJYmG"
      },
      "source": [
        "## ðŸ“¦Export the model\n",
        "After training, you can export the model to the format for deployment. SSCMA supports exporting to ONNX, and TensorFlow Lite at present.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "```bash\n",
        "python3 tools/export.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AZvhUwxJYmG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "with open('Gesture_Detection_Swift-YOLO_192/last_checkpoint', 'r') as f:\n",
        "\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE4wUDLRJYmG"
      },
      "outputs": [],
      "source": [
        "!sscma.export configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=12 \\\n",
        "    epochs=30  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZhsbJATJYmG"
      },
      "source": [
        "### ðŸ“Evaluate the model\n",
        "After exporting the model, you can evaluate the model on the test dataset.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "\n",
        "```bash\n",
        "python3 tools/inference.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V55gw4MaJYmH"
      },
      "source": [
        "### Evaluate the PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ki9TUrpJYmH"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YBIc2OSJYmH"
      },
      "source": [
        "### Evaluate the ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM_DZFtnJYmH"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YqhCooKJYmI"
      },
      "source": [
        "### Evaluate the TFLite FLOAT32 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6SHO6QYJYmI"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=3 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sMLOB8-JYmI"
      },
      "source": [
        "### Evaluate the TFLite INT8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKV9oea6JYmI"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=Gesture_Detection_Swift-YOLO_192 \\\n",
        "    num_classes=12 \\\n",
        "    epochs=10  \\\n",
        "    height=192 \\\n",
        "    width=192 \\\n",
        "    data_root=Gesture_Detection_Swift-YOLO_192/dataset/ \\\n",
        "    load_from=Gesture_Detection_Swift-YOLO_192/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcrkCRC5JYmI"
      },
      "source": [
        "## ðŸ¤– Deploy the model\n",
        "After model training, evaluation and export, you can deploy the model to your device. You can refer to [Documentation](https://sensecraftma.seeed.cc/deploy/overview) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEoiJqjFJYmI"
      },
      "outputs": [],
      "source": [
        "%ls -lh Gesture_Detection_Swift-YOLO_192/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_-fDN0FJYmJ"
      },
      "source": [
        "### Thanks for Trying Out SSCMA ðŸŽ‰\n",
        "\n",
        "Congratulations, you have completed this tutorial. If you are interested in more application scenarios or our projects, please feel free to give [SSCMA](https://github.com/Seeed-Studio/ModelAssistant) a star âœ¨ on GitHub.\n",
        "\n",
        "If you have any questions about this tutorial, please also feel free to [submit an issue](https://github.com/Seeed-Studio/ModelAssistant/issues)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}